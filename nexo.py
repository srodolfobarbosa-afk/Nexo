import os
import requests
import io
import sys
import time
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from dotenv import load_dotenv
from flask import Flask, render_template, request, jsonify, send_from_directory

# Cria a sua aplica√ß√£o Flask
app = Flask(__name__)

def get_api_key():
    """
    Carrega e retorna a chave de API do arquivo .env.
    """
    try:
        load_dotenv()
        api_key = os.getenv("NEXO_API_KEY")
        if not api_key:
            return None 
        return api_key
    except Exception as e:
        print(f"Erro: {e}")
        return None

@app.route("/")
def interface_chat():
    """
    Rota principal que serve a interface de chat
    """
    return send_from_directory("static", "index.html")



@app.route("/chat", methods=["POST"])
def processar_missao():
    """
    Rota para processar miss√µes via chat
    """
    try:
        data = request.get_json()
        user_message = data.get("message", "")
        
        if not user_message:
            return jsonify({"response": "Por favor, envie uma mensagem v√°lida."})
        
        from core.auto_construction import AutoConstructionModule
        # Instanciar o m√≥dulo de auto-constru√ß√£o
        def llm_caller(prompt, context):
            # Aqui voc√™ pode integrar com seu LLM real
            return '{"overview": "Miss√£o processada", "components": ["auto"]}'
        auto_constructor = AutoConstructionModule(llm_caller)
        
        # Capturar a sa√≠da do console para retornar ao usu√°rio
        old_stdout = sys.stdout
        redirected_output = io.StringIO()
        sys.stdout = redirected_output

        try:
            # Processar a miss√£o usando o AutoConstructionModule
            result = auto_constructor.auto_construct_feature(user_message)
            output = redirected_output.getvalue()
            return jsonify({"response": f"Resultado da miss√£o: {result}\nLogs: {output}"})
        except Exception as e:
            output = redirected_output.getvalue()
            return jsonify({"response": f"Houve um erro ao processar a miss√£o: {e}\nLogs: {output}"}), 500
        finally:
            sys.stdout = old_stdout
        
    except Exception as e:
        print(f"Erro ao processar miss√£o: {e}")
        return jsonify({"response": f"Erro interno: {e}"}), 500


# Servir arquivos est√°ticos
@app.route("/static/<path:filename>")
def static_files(filename):
    return send_from_directory("static", filename)

# Registrar rotas da API para integra√ß√£o com Telegram
try:
    from api_endpoints import register_api_routes
    register_api_routes(app)
    print("‚úÖ Rotas da API do Telegram registradas")
except ImportError as e:
    print(f"‚ö†Ô∏è N√£o foi poss√≠vel carregar rotas da API: {e}")

def auto_evolution_persistente(missao, max_retries=9999, cooldown=30):
    """
    Fun√ß√£o para tentar processar uma miss√£o v√°rias vezes em caso de falha,
    com um tempo de espera (cooldown) entre as tentativas.
    """
    from core.auto_construction import AutoConstructionModule
    def llm_caller(prompt, context):
        # Aqui voc√™ pode integrar com seu LLM real
        return '{"overview": "Miss√£o processada", "components": ["auto"]}'
    auto_constructor = AutoConstructionModule(llm_caller)
    tentativas = 0
    while tentativas < max_retries:
        try:
            print(f"[Nexo] Tentativa {tentativas+1} de auto-evolu√ß√£o para miss√£o: {missao}")
            result = auto_constructor.auto_construct_feature(missao)
            print(f"[Nexo] Miss√£o conclu√≠da: {result}")
            return result
        except Exception as e:
            print(f"[Nexo] Erro na miss√£o: {e}. Entrando em modo de auto-corre√ß√£o. Nova tentativa em {cooldown} segundos...")
            time.sleep(cooldown)
            tentativas += 1
    print("[Nexo] Limite de tentativas atingido. Miss√£o n√£o conclu√≠da.")
    return None

@app.route("/agentes-log")
def agentes_log():
    # L√™ registros da mem√≥ria local (memoria_curto_prazo.json)
    memoria_path = os.path.join(os.path.dirname(__file__), 'memoria_curto_prazo.json')
    if not os.path.exists(memoria_path):
        return jsonify([])
    try:
        with open(memoria_path, 'r') as f:
            dados = json.load(f)
        # Extrai registros de ferramentas e outras a√ß√µes
        logs = []
        if 'ferramentas' in dados:
            for nome, info in dados['ferramentas'].items():
                entry = info.copy()
                entry['nome'] = nome
                logs.append(entry)
        # Adicione outros tipos de registro se necess√°rio
        return jsonify(logs)
    except Exception as e:
        return jsonify({'erro': str(e)})

@app.route("/agentes_log.html")
def agentes_log_html():
    return send_from_directory("static", "agentes_log.html")

if __name__ == "__main__":
    import socket
    def find_free_port(start_port=5000, max_tries=10):
        port = start_port
        for _ in range(max_tries):
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                if s.connect_ex(("127.0.0.1", port)) != 0:
                    return port
                port += 1
        raise RuntimeError("N√£o h√° portas livres dispon√≠veis.")

    port = find_free_port(int(os.environ.get("PORT", 5000)))
    print("üå± EcoGuardians - Sistema Iniciado")
    print("ü§ñ Nexo G√™nesis - Agente Orquestrador Ativo")
    print(f"üí¨ Interface de Chat dispon√≠vel em: http://127.0.0.1:{port}")
    print("ü§ñ API do Telegram Bot integrada")
    app.run(debug=True, host="0.0.0.0", port=port)

